{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/titanic3.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['survived']\n",
    "X = df.drop(columns='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(columns=['name', 'ticket', 'cabin', 'body',\n",
    "                    'home.dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['pclass', 'sex', \n",
    "                               'embarked', 'boat'], dummy_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 1*(y == 1) + -1*(y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feat = ['age', 'sibsp', 'parch', 'fare']\n",
    "for feat in num_feat:\n",
    "    X[feat] = X[feat].fillna(X[feat].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_target(n_classes, target):\n",
    "    if n_classes > 1:\n",
    "        target = pd.get_dummies(target)\n",
    "    return target    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_y = one_hot_target(1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100 loss: 1.136217 train_acc: 0.596944\n",
      "epoch:  200 loss: 1.070203 train_acc: 0.600764\n",
      "epoch:  300 loss: 1.007717 train_acc: 0.612225\n",
      "epoch:  400 loss: 0.948816 train_acc: 0.618911\n",
      "epoch:  500 loss: 0.893534 train_acc: 0.631328\n",
      "epoch:  600 loss: 0.841894 train_acc: 0.644699\n",
      "epoch:  700 loss: 0.793923 train_acc: 0.663801\n",
      "epoch:  800 loss: 0.749654 train_acc: 0.674308\n",
      "epoch:  900 loss: 0.709109 train_acc: 0.685769\n",
      "epoch: 1000 loss: 0.672260 train_acc: 0.694365\n",
      "epoch: 1100 loss: 0.639000 train_acc: 0.702006\n",
      "epoch: 1200 loss: 0.609131 train_acc: 0.713467\n",
      "epoch: 1300 loss: 0.582375 train_acc: 0.730659\n",
      "epoch: 1400 loss: 0.558407 train_acc: 0.744986\n",
      "epoch: 1500 loss: 0.536882 train_acc: 0.751671\n",
      "epoch: 1600 loss: 0.517461 train_acc: 0.761223\n",
      "epoch: 1700 loss: 0.499834 train_acc: 0.775549\n",
      "epoch: 1800 loss: 0.483728 train_acc: 0.782235\n",
      "epoch: 1900 loss: 0.468920 train_acc: 0.787966\n",
      "epoch: 2000 loss: 0.455226 train_acc: 0.795606\n",
      "epoch: 2100 loss: 0.442499 train_acc: 0.800382\n",
      "epoch: 2200 loss: 0.430618 train_acc: 0.807068\n",
      "epoch: 2300 loss: 0.419481 train_acc: 0.813754\n",
      "epoch: 2400 loss: 0.409003 train_acc: 0.827125\n",
      "epoch: 2500 loss: 0.399108 train_acc: 0.833811\n",
      "epoch: 2600 loss: 0.389734 train_acc: 0.844317\n",
      "epoch: 2700 loss: 0.380823 train_acc: 0.852913\n",
      "epoch: 2800 loss: 0.372329 train_acc: 0.853868\n",
      "epoch: 2900 loss: 0.364209 train_acc: 0.860554\n",
      "epoch: 3000 loss: 0.356428 train_acc: 0.866285\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_feats = X_train.shape[1]\n",
    "\n",
    "w = tf.Variable(tf.random_normal(shape=[n_feats, 1]), name='weights')\n",
    "b = tf.Variable(tf.random_normal(shape=[1, 1]), name='bias')\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_feats])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "\n",
    "Y_pred = tf.matmul(X, w) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Y_pred, labels=Y),\n",
    "                      name='loss')\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "prediction = tf.round(tf.sigmoid(Y_pred))\n",
    "correct = tf.cast(tf.equal(prediction, Y), dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(correct)\n",
    "\n",
    "\n",
    "iter_num = 3000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(iter_num):\n",
    "        feed_dict = {X: X_train, Y: np.matrix(y_train).T}\n",
    "        _, temp_loss = sess.run([opt, loss], feed_dict)\n",
    "        temp_train_acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        w_out = sess.run(w, feed_dict=feed_dict)\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print('epoch: {:4d} loss: {:5f} train_acc: {:5f}'.format(epoch + 1, temp_loss,\n",
    "                                                                              temp_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
