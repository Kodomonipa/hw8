{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf LR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lr_model(X_train, y_train, X_test, y_test,\n",
    "                   iter_num, n_classes=2):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    n_feats = X_train.shape[1]\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        n_classes -= 1\n",
    "        \n",
    "    w = tf.Variable(tf.random_normal(shape=[n_feats, n_classes]),\n",
    "                    name='weights')\n",
    "    b = tf.Variable(tf.random_normal(shape=[1, n_classes]),\n",
    "                    name='bias')\n",
    "\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, n_feats])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes])\n",
    "\n",
    "    Y_pred = tf.matmul(X, w) + b\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Y_pred, labels=Y),\n",
    "                          name='loss')\n",
    "\n",
    "    opt = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "    prediction = tf.round(tf.sigmoid(Y_pred))\n",
    "    \n",
    "    if n_classes == 1:        \n",
    "        correct = tf.cast(tf.equal(prediction, Y), dtype=tf.float32)\n",
    "    else:\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "        \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer()) \n",
    "        for epoch in range(iter_num):\n",
    "            feed_dict = {X: X_train, Y: np.matrix(y_train).T}\n",
    "            _, temp_loss = sess.run([opt, loss], feed_dict)\n",
    "            temp_train_acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "            b_out, w_out = sess.run([b, w], feed_dict=feed_dict)\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print('epoch: {:4d} loss: {:5f} train accuracy: {:5f}'.format(epoch + 1,\n",
    "                                                                              temp_loss,\n",
    "                                                                              temp_train_acc))\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: np.matrix(y_test).T})\n",
    "        print()\n",
    "        print('test accuracy: {:5f}'.format(test_acc))\n",
    "    pass           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_df = pd.read_excel('data/titanic3.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanic_df['survived']\n",
    "X = titanic_df.drop(columns=['survived', 'name',\n",
    "                             'ticket', 'cabin', 'body',\n",
    "                             'home.dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['pclass', 'sex', \n",
    "                               'embarked', 'boat'], dummy_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feat = ['age', 'sibsp', 'parch', 'fare']\n",
    "for feat in num_feat:\n",
    "    X[feat] = X[feat].fillna(X[feat].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100 loss: 0.999018 train accuracy: 0.565425\n",
      "epoch:  200 loss: 0.945618 train accuracy: 0.577841\n",
      "epoch:  300 loss: 0.895660 train accuracy: 0.582617\n",
      "epoch:  400 loss: 0.849084 train accuracy: 0.583572\n",
      "epoch:  500 loss: 0.805798 train accuracy: 0.593123\n",
      "epoch:  600 loss: 0.765676 train accuracy: 0.602674\n",
      "epoch:  700 loss: 0.728569 train accuracy: 0.638968\n",
      "epoch:  800 loss: 0.694309 train accuracy: 0.666667\n",
      "epoch:  900 loss: 0.662712 train accuracy: 0.698185\n",
      "epoch: 1000 loss: 0.649792 train accuracy: 0.708691\n",
      "epoch: 1100 loss: 0.626216 train accuracy: 0.731614\n",
      "epoch: 1200 loss: 0.603875 train accuracy: 0.747851\n",
      "epoch: 1300 loss: 0.582756 train accuracy: 0.755492\n",
      "epoch: 1400 loss: 0.562818 train accuracy: 0.759312\n",
      "epoch: 1500 loss: 0.544010 train accuracy: 0.771729\n",
      "epoch: 1600 loss: 0.526272 train accuracy: 0.779370\n",
      "epoch: 1700 loss: 0.509544 train accuracy: 0.797517\n",
      "epoch: 1800 loss: 0.493764 train accuracy: 0.800382\n",
      "epoch: 1900 loss: 0.478872 train accuracy: 0.805158\n",
      "epoch: 2000 loss: 0.464811 train accuracy: 0.817574\n",
      "\n",
      "test accuracy: 0.847328\n"
     ]
    }
   ],
   "source": [
    "train_lr_model(X_train, y_train, X_test, y_test, 2000, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, y_test = pd.get_dummies(y_train), pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1047 samples, validate on 262 samples\n",
      "Epoch 1/20\n",
      "1047/1047 [==============================] - 0s 289us/step - loss: 5.1822 - acc: 0.3820 - val_loss: 4.2573 - val_acc: 0.3817\n",
      "Epoch 2/20\n",
      "1047/1047 [==============================] - 0s 137us/step - loss: 3.0624 - acc: 0.3811 - val_loss: 1.8807 - val_acc: 0.3779\n",
      "Epoch 3/20\n",
      "1047/1047 [==============================] - 0s 155us/step - loss: 1.2610 - acc: 0.3820 - val_loss: 0.8962 - val_acc: 0.4580\n",
      "Epoch 4/20\n",
      "1047/1047 [==============================] - 0s 160us/step - loss: 0.7513 - acc: 0.5301 - val_loss: 0.5908 - val_acc: 0.7366\n",
      "Epoch 5/20\n",
      "1047/1047 [==============================] - 0s 152us/step - loss: 0.5690 - acc: 0.7373 - val_loss: 0.5155 - val_acc: 0.7901\n",
      "Epoch 6/20\n",
      "1047/1047 [==============================] - 0s 145us/step - loss: 0.5183 - acc: 0.7736 - val_loss: 0.4889 - val_acc: 0.7786\n",
      "Epoch 7/20\n",
      "1047/1047 [==============================] - 0s 217us/step - loss: 0.4914 - acc: 0.7784 - val_loss: 0.4703 - val_acc: 0.7901\n",
      "Epoch 8/20\n",
      "1047/1047 [==============================] - 0s 224us/step - loss: 0.4701 - acc: 0.7832 - val_loss: 0.4504 - val_acc: 0.7901\n",
      "Epoch 9/20\n",
      "1047/1047 [==============================] - 0s 196us/step - loss: 0.4507 - acc: 0.7956 - val_loss: 0.4365 - val_acc: 0.8244\n",
      "Epoch 10/20\n",
      "1047/1047 [==============================] - 0s 166us/step - loss: 0.4353 - acc: 0.8262 - val_loss: 0.4185 - val_acc: 0.8130\n",
      "Epoch 11/20\n",
      "1047/1047 [==============================] - 0s 206us/step - loss: 0.4183 - acc: 0.8204 - val_loss: 0.4054 - val_acc: 0.8664\n",
      "Epoch 12/20\n",
      "1047/1047 [==============================] - 0s 186us/step - loss: 0.4052 - acc: 0.8615 - val_loss: 0.3896 - val_acc: 0.8511\n",
      "Epoch 13/20\n",
      "1047/1047 [==============================] - 0s 199us/step - loss: 0.3911 - acc: 0.8586 - val_loss: 0.3767 - val_acc: 0.8702\n",
      "Epoch 14/20\n",
      "1047/1047 [==============================] - 0s 216us/step - loss: 0.3793 - acc: 0.8711 - val_loss: 0.3644 - val_acc: 0.8855\n",
      "Epoch 15/20\n",
      "1047/1047 [==============================] - 0s 208us/step - loss: 0.3647 - acc: 0.8777 - val_loss: 0.3533 - val_acc: 0.8893\n",
      "Epoch 16/20\n",
      "1047/1047 [==============================] - 0s 191us/step - loss: 0.3542 - acc: 0.8844 - val_loss: 0.3429 - val_acc: 0.8969\n",
      "Epoch 17/20\n",
      "1047/1047 [==============================] - 0s 179us/step - loss: 0.3445 - acc: 0.8825 - val_loss: 0.3329 - val_acc: 0.9008\n",
      "Epoch 18/20\n",
      "1047/1047 [==============================] - 0s 208us/step - loss: 0.3337 - acc: 0.8883 - val_loss: 0.3239 - val_acc: 0.9160\n",
      "Epoch 19/20\n",
      "1047/1047 [==============================] - 0s 169us/step - loss: 0.3249 - acc: 0.8978 - val_loss: 0.3152 - val_acc: 0.9084\n",
      "Epoch 20/20\n",
      "1047/1047 [==============================] - 0s 170us/step - loss: 0.3148 - acc: 0.9007 - val_loss: 0.3064 - val_acc: 0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d9c3016a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feat = X_train.shape[1]\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation='softmax', input_shape=(n_feat,)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       162\n",
      "          1       0.99      0.80      0.88       100\n",
      "\n",
      "avg / total       0.93      0.92      0.92       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_scores = model.predict(X_test)\n",
    "y_predicted = y_predicted_scores.argmax(axis=1)\n",
    "\n",
    "print('Classification report\\n')\n",
    "print(classification_report(np.matrix(y_test).argmax(axis=1), y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf Thyroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thyroid_df = pd.read_csv('data/dataset_57_hypothyroid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(все действия - как в hw3, где был тот же датасет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thyroid_df = thyroid_df.drop(['query_on_thyroxine', \n",
    "                              'on_antithyroid_medication',\n",
    "                              'pregnant', 'thyroid_surgery',\n",
    "                              'I131_treatment', 'lithium',\n",
    "                              'goitre', 'referral_source',\n",
    "                              'TBG', 'TSH_measured',\n",
    "                              'T3_measured', 'TT4_measured',\n",
    "                              'FTI_measured', 'TBG_measured',\n",
    "                              'T4U_measured'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "for feat in num_features:\n",
    "    thyroid_df[feat] = pd.to_numeric(thyroid_df[feat], errors='coerce')\n",
    "    feat_median = thyroid_df[feat].median()\n",
    "    thyroid_df[feat] = thyroid_df[feat].replace(np.nan, feat_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thyroid_df['age>45'] = 1*(thyroid_df['age'] > 45)\n",
    "thyroid_df = thyroid_df.drop('age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thyroid_df['sex'] = thyroid_df['sex'].replace('?', 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = thyroid_df['Class']\n",
    "X = thyroid_df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    num_features.remove('age')\n",
    "except:\n",
    "    pass\n",
    "num_df = X[num_features]\n",
    "cat_df = X.drop(num_features, axis=1)\n",
    "cat_df = pd.get_dummies(cat_df)\n",
    "X = pd.concat([cat_df, num_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dum = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_dum, test_size=0.2,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100 loss: 2.724524 train accuracy: 0.913822\n",
      "epoch:  200 loss: 1.725437 train accuracy: 0.920119\n",
      "epoch:  300 loss: 1.270614 train accuracy: 0.921777\n",
      "epoch:  400 loss: 0.829953 train accuracy: 0.921445\n",
      "epoch:  500 loss: 0.574201 train accuracy: 0.925091\n",
      "epoch:  600 loss: 0.366576 train accuracy: 0.927743\n",
      "epoch:  700 loss: 0.259197 train accuracy: 0.935698\n",
      "epoch:  800 loss: 0.247308 train accuracy: 0.938018\n",
      "epoch:  900 loss: 0.237851 train accuracy: 0.940338\n",
      "epoch: 1000 loss: 0.229983 train accuracy: 0.942990\n",
      "epoch: 1100 loss: 0.223224 train accuracy: 0.943321\n",
      "epoch: 1200 loss: 0.217165 train accuracy: 0.943653\n",
      "epoch: 1300 loss: 0.211641 train accuracy: 0.943984\n",
      "epoch: 1400 loss: 0.206590 train accuracy: 0.944316\n",
      "epoch: 1500 loss: 0.201966 train accuracy: 0.943984\n",
      "epoch: 1600 loss: 0.197693 train accuracy: 0.944647\n",
      "epoch: 1700 loss: 0.193761 train accuracy: 0.944978\n",
      "epoch: 1800 loss: 0.190460 train accuracy: 0.944978\n",
      "epoch: 1900 loss: 0.187457 train accuracy: 0.944316\n",
      "epoch: 2000 loss: 0.184600 train accuracy: 0.943984\n",
      "\n",
      "test accuracy: 0.952318\n"
     ]
    }
   ],
   "source": [
    "train_lr_model(X_train, y_train.T, X_test, y_test.T, 2000, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3017 samples, validate on 755 samples\n",
      "Epoch 1/5\n",
      "3017/3017 [==============================] - 1s 179us/step - loss: 1.0484 - acc: 0.9284 - val_loss: 1.1113 - val_acc: 0.9285\n",
      "Epoch 2/5\n",
      "3017/3017 [==============================] - 0s 134us/step - loss: 1.0023 - acc: 0.9357 - val_loss: 1.0820 - val_acc: 0.9311\n",
      "Epoch 3/5\n",
      "3017/3017 [==============================] - 0s 140us/step - loss: 0.9905 - acc: 0.9370 - val_loss: 1.0687 - val_acc: 0.9325\n",
      "Epoch 4/5\n",
      "3017/3017 [==============================] - 0s 138us/step - loss: 0.9833 - acc: 0.9370 - val_loss: 1.0585 - val_acc: 0.9325\n",
      "Epoch 5/5\n",
      "3017/3017 [==============================] - 0s 144us/step - loss: 0.9527 - acc: 0.9387 - val_loss: 1.0356 - val_acc: 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1dfd57bb38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#K.clear_session()\n",
    "#sess = tf.Session()\n",
    "#K.set_session(sess)\n",
    "\n",
    "n_feat = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='softmax', input_shape=(n_feat,)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        39\n",
      "          1       0.94      1.00      0.97       697\n",
      "          2       0.85      0.58      0.69        19\n",
      "\n",
      "avg / total       0.89      0.94      0.91       755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_scores = model.predict(X_test)\n",
    "y_predicted = y_predicted_scores.argmax(axis=1)\n",
    "\n",
    "print('Classification report\\n')\n",
    "print(classification_report(np.matrix(y_test).argmax(axis=1), y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
